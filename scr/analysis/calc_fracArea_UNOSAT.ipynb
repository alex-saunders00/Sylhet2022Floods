{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b3dd4f-6c86-456a-b7c2-a73985a91ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project: NIP\n",
    "# Subroject: Sylhet Floods, June 2022\n",
    "## Script: fracArea_timeSeries_UNOSAT.ipynb\n",
    "This script generates a time series of the fractional inundated area, from the outputs of the UNOSAT surface water product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b5fc22-8f3a-4e36-99b0-8c2240b04ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from itertools import chain\n",
    "from pyproj import Transformer\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as colors\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import copy\n",
    "import collections\n",
    "from shapely.geometry import mapping\n",
    "import pycrs\n",
    "from shapely.geometry import Polygon\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e090b766-cc0a-4cdc-8361-29e63c1f419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root path\n",
    "rootPath = Path('Z:/media/mule/Projects/NASA/NIP/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d03fd0-febb-4440-9f3d-26aa6efaaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path for the Helpers modules\n",
    "module_path = os.path.abspath(os.path.join('C:/Users/alexsaunders/Documents/01_uoa/04_git/NIP/Sylhet/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a368b748-f66c-49fa-b591-8eecf9d90459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Helpers.prepare_flood_raster' from 'C:\\\\Users\\\\alexsaunders\\\\Documents\\\\01_uoa\\\\04_git\\\\NIP\\\\Sylhet\\\\Helpers\\\\prepare_flood_raster.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import module from analyse_modifiedDevries containing helpful functions to use\n",
    "import importlib\n",
    "import Helpers.analyse_modifiedDevries as analyse_DV\n",
    "importlib.reload(analyse_DV)\n",
    "import Helpers.prepare_flood_raster as prep_raster\n",
    "importlib.reload(prep_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e41834-44f1-4242-ab85-390dc2e42399",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART 1: Define the ROI(s) for computing fractional flooded area\n",
    "Load in the admin areas and gauge locations, create some buffer sizes around the gauges to use as ROI for computing FFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f0c12c-346b-4fba-b53b-60dc72dec4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('Z:/media/mule/Projects/NASA/NIP/Data/Raster/SylhetUNOSAT/S1_20220525_WaterExtent_NE_allTouchTrue.tif')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNOSATPath = rootPath/'Raster/SylhetUNOSAT'\n",
    "mosaics = [file for file in (UNOSATPath).iterdir() if file.is_file() and 'allTouchTrue' in str(file) and '20220525_W' in str(file)]\n",
    "mosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b0a309-1f4b-403f-9925-4832151d18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ROI geometry from shapefile\n",
    "adminShapePath = rootPath/'Shapefiles/AdminHDX'\n",
    "districts = gpd.read_file(adminShapePath/'bgd_admbnda_adm2_bbs_20201113.shp')\n",
    "upazillas = gpd.read_file(adminShapePath/'bgd_admbnda_adm3_bbs_20201113.shp')\n",
    "sylhet_dist = districts[districts['ADM2_EN']=='Sylhet']\n",
    "sylhet_upa = upazillas[upazillas['ADM3_EN']=='Sylhet Sadar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d302d71-252e-4741-8b7f-87909439fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or instead create the ROI as a buffer around the gauge locations\n",
    "\n",
    "# Import the gauge station locations\n",
    "gaugePath = rootPath/'Stream_Gauge/StreamGaugeShapefiles'\n",
    "gaugeLocs = gpd.read_file(gaugePath/'streamgaugew_division.shp') # read the file as a geopandas\n",
    "\n",
    "# Create buffer around all gauges - use several different buffer sizes starting from 100 m, to 1 km\n",
    "gaugeLocsGeoms = gaugeLocs.geometry\n",
    "buffer_sizes = [5, 10, 15]#[0.1, 0.2, 0.5, 1]\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "for buffer_size in buffer_sizes:\n",
    "    \n",
    "    # Add new field to locs geodataframe to store the buffer geometries\n",
    "    gaugeLocs['buffer_'+str(buffer_size)] = 0\n",
    "\n",
    "    # For each gaugeLoc, get the buffer and add back to the geodataframe\n",
    "    for i in range(0, len(gaugeLocs)):\n",
    "        gaugeLocGeom = gaugeLocsGeoms[i]\n",
    "        buffer = analyse_DV.geodesic_point_buffer(gaugeLocGeom.y, gaugeLocGeom.x, buffer_size) # lat, lon, buffer (in km)\n",
    "        gaugeLocs['buffer_'+str(buffer_size)][i] = Polygon(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ec9d89-1684-4c3c-8de1-b342f04f33fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SW172.5', 'SW173', 'SW175.5', 'SW251', 'SW266', 'SW267']\n"
     ]
    }
   ],
   "source": [
    "# Define the gauges in Sylhet District\n",
    "streamGaugeDataPath = rootPath/'Stream_Gauge/'\n",
    "gauges_in_sylhet = pd.read_csv(streamGaugeDataPath/'streamgauges_SylhetDist.csv', header=0)\n",
    "gauges_in_sylhet = list(gauges_in_sylhet['streamvect'])\n",
    "gaugeDataSummaryMaster = pd.read_csv(streamGaugeDataPath/'CombinedAll2004-2022/Combined/summary.csv', header=0)\n",
    "gauges = [match for match in gauges_in_sylhet if match in list(gaugeDataSummaryMaster['stationID'][np.logical_and(~np.isnan(gaugeDataSummaryMaster['danger_level']),gaugeDataSummaryMaster['danger_level']<1000)])]\n",
    "print(gauges)\n",
    "gauges_in_sylhet_geom = gaugeLocs[gaugeLocs['streamvect'].isin(gauges_in_sylhet)]\n",
    "gauges_geom = gaugeLocs[gaugeLocs['streamvect'].isin(gauges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63f768e-a6ab-48fe-8c1b-69b6a8d0ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which gauge to use as the ROI for FFA time series\n",
    "#SW267 is Sylhet\n",
    "#SW269 is Sunamganj\n",
    "#gauge_sylhet = gaugeLocs[gaugeLocs['streamvect']=='SW267']\n",
    "#gauge_sunamganj = gaugeLocs[gaugeLocs['streamvect']=='SW269']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8509486-96b8-4da3-9a0a-b92bfd104ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauges_list = list(chain.from_iterable([list(gauges_geom['streamvect']+'_'+str(buffer_size)+'km') for buffer_size in buffer_sizes]))\n",
    "gauges_geom_list = list(chain.from_iterable([list(gauges_geom['buffer_'+str(buffer_size)]) for buffer_size in buffer_sizes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab437bf5-23bb-4366-9a89-8014a997faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single geodataframe of ROIs over which to calculate FFA\n",
    "rois = {'id': ['Sylhet_District', 'Sylhet_Upazilla']+gauges_list, \n",
    "        'geometry': list(sylhet_dist.geometry)+list(sylhet_upa.geometry)+gauges_geom_list}\n",
    "rois_gdf = gpd.GeoDataFrame(rois, geometry='geometry', crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acf232-ba34-47a6-95c1-adb6f641230a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART 2: Compute the fractional inundated area at each timestep\n",
    "For each date, extract the fractional inundated area for the specified ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bd535b-90c2-4f50-98b1-4c8b8903897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('Z:/media/mule/Projects/NASA/NIP/Data/Raster/SylhetUNOSAT/S1_20220525_WaterExtent_NE_allTouchTrue.tif')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674c8c34-e752-4446-8906-8f5d97785311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dates: ['20220525']\n"
     ]
    }
   ],
   "source": [
    "# Get the dates of images\n",
    "dates = ['20220525']\n",
    "print(len(dates), 'dates:', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e662ec-26a9-4154-8935-e245c9ad311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to create temp raster file for using in masking - ONLY NEEDS TO BE RUN ONCE\n",
    "\n",
    "# Run the function which creates a raster of values 10, the same dimensions as the flood raster, to be used for clipping to the ROI later\n",
    "# date1 = '20220604'\n",
    "# mosaic = [mosaic for mosaic in mosaics if date1 in str(mosaic)][0]\n",
    "# analyse_DV.create_temp_raster_for_mask(mosaic, rootPath, inputPath) # creates raster_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0258b31f-3d1b-4660-a53f-34bb9c6832e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the temp raster in and intersect it with the ROI - this will be used for clipping to the ROI since it contains values of 10\n",
    "# Also load the Devries raster, which will be used to reproject and match the GFM raster, to make the rest of the processing workflow the same\n",
    "DevriesPath = rootPath/'Raster/Sylhet/Sen1MitchellSingleOrbit/Mosaic'\n",
    "raster_tmp = rasterio.open(DevriesPath/'temp.tif') # can recreate this file if needs for a different ROI area by rerunning the above function\n",
    "Devries_mosaics = [file for file in (DevriesPath).iterdir() if file.is_file() and '2022' in str(file)]\n",
    "#raster_Devries = rasterio.open(Devries_mosaics[0])\n",
    "raster_Devries = prep_raster.load_raster_for_comparison(Devries_mosaics[0], -20) # raster to match projection and extent, value to set not valid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d16aaa7-c58d-44b0-9b53-2eac7ce8755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to get the fractional flooded area for all image dates, for all the provided ROIs\n",
    "# note that raster_tmp will need to be recreated if using images with a different extent (but otherwise does not need to be recreated)\n",
    "# fracFloodArea_sylhetDist = analyse_DV.get_fracArea_timeSeries_GFM(mosaics, raster_tmp, raster_Devries, sylhet_dist)\n",
    "# fracFloodArea_sylhetUpa = analyse_DV.get_fracArea_timeSeries_GFM(mosaics, raster_tmp, raster_Devries, sylhet_upa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb0f907e-5b5a-4d58-9ce2-1b895697aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mosaic: 20220525 Z:\\media\\mule\\Projects\\NASA\\NIP\\Data\\Raster\\SylhetUNOSAT\\S1_20220525_WaterExtent_NE_allTouchTrue.tif\n",
      "Counter({0.0: 27936043, 11.0: 17547711, 10.0: 16613392, 1.0: 5111349})\n",
      "ROI % water at 20220525 for Sylhet_District: 51.4%\n",
      "Counter({0.0: 42592958, 1.0: 21439997, 10.0: 1956477, 11.0: 1219063})\n",
      "ROI % water at 20220525 for Sylhet_Upazilla: 38.4%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get the number of pixels of water for each date for the ROI only (pixel values in ROI have been shifted by +10 from original values)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m water_roi_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(water_roi\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()))))\n\u001b[1;32m---> 37\u001b[0m counter_roi \u001b[38;5;241m=\u001b[39m \u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwater_roi_vals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 10 = none, 11 = water, other = invalid or outside ROI\u001b[39;00m\n\u001b[0;32m     38\u001b[0m pctWater_roi \u001b[38;5;241m=\u001b[39m counter_roi[\u001b[38;5;241m11\u001b[39m] \u001b[38;5;241m/\u001b[39m (counter_roi[\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m+\u001b[39m counter_roi[\u001b[38;5;241m11\u001b[39m])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(counter_roi)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_rioxarray38_\\lib\\collections\\__init__.py:552\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m \n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28msuper\u001b[39m(Counter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 552\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_rioxarray38_\\lib\\collections\\__init__.py:638\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    637\u001b[0m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[1;32m--> 638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the function to get the fractional flooded area for all image dates, for all the provided ROIs\n",
    "mosaic_dates = []\n",
    "pctWaters = []\n",
    "rois_list = []\n",
    "\n",
    "# Loop through image dates\n",
    "for n, mosaic in enumerate(mosaics):\n",
    "    \n",
    "    # Get the date\n",
    "    mosaic_date = dates[n]\n",
    "    print('Mosaic:', mosaic_date, mosaic)\n",
    "\n",
    "    # Load the raster using rioxarray\n",
    "    raster = prep_raster.load_raster_for_comparison(mosaic, -10)\n",
    "\n",
    "    # Reproject and match the GFM raster to the modified Devries raster to make the processing the same\n",
    "    raster_reproj = prep_raster.reproj_match_raster(raster, raster_Devries)\n",
    "\n",
    "    # Set the water values to 1\n",
    "    water = copy.copy(raster_reproj)\n",
    "    water.values[water.values==1]=1\n",
    "    water.values[water.values!=1]=0\n",
    "    \n",
    "    # Loop through all ROI geometries\n",
    "    for j in range(len(rois_gdf)):\n",
    "\n",
    "        # Run the function to create the raster mask for the ROI, using the temp raster containing all values 10\n",
    "        roiID = rois_gdf.id[j]\n",
    "        roi = rois_gdf.loc[[j]]\n",
    "        roi_mask = analyse_DV.create_roi_mask(raster_tmp, roi)\n",
    "\n",
    "        # Apply the mask to the water_sum raster by performing an array sum operation\n",
    "        water_roi = np.add(water, roi_mask)\n",
    "\n",
    "        # Get the number of pixels of water for each date for the ROI only (pixel values in ROI have been shifted by +10 from original values)\n",
    "        water_roi_vals = list(chain.from_iterable(list(chain.from_iterable(water_roi.values.tolist()))))\n",
    "        counter_roi = collections.Counter(water_roi_vals) # 10 = none, 11 = water, other = invalid or outside ROI\n",
    "        pctWater_roi = counter_roi[11] / (counter_roi[10] + counter_roi[11])\n",
    "        print(counter_roi)\n",
    "        print('ROI % water at {0} for {1}: {2:2.1f}%'.format(mosaic_date, roiID, pctWater_roi*100))\n",
    "        \n",
    "        # Record the results for the date and ROI\n",
    "        mosaic_dates.append(mosaic_date)\n",
    "        rois_list.append(roiID)\n",
    "        pctWaters.append(pctWater_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e3132b-b8bd-4769-94e0-f9308fa6bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of the results - fractional flooded area\n",
    "fracFloodArea = pd.DataFrame(data = [mosaic_dates, rois_list, pctWaters], index = ['Date','ROI','FFA']).T\n",
    "fracFloodArea = fracFloodArea.pivot(index='Date', columns='ROI', values='FFA')\n",
    "fracFloodArea.index = pd.to_datetime(fracFloodArea.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe08ccac-5ed6-4b5d-aded-3350d8f83668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results as csv\n",
    "outputPath = rootPath/'Table/SylhetFracFloodedArea'\n",
    "outputPath.mkdir(exist_ok=True)\n",
    "pd.DataFrame.to_csv(fracFloodArea, outputPath/'FFA_sylhet_allROI_allGauges_UNOSATallTouchTrue_25.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4819eff-b584-4d32-836d-38d1d99b36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If required, read back in from csv table\n",
    "# fracFloodArea = pd.read_csv(rootPath/'Table/SylhetFracFloodedArea/FFA_sylhet_allROI_allGauges_GFM.csv', index_col='Date')\n",
    "# fracFloodArea.index = pd.to_datetime(fracFloodAreaBuffers.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
